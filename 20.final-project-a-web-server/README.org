* 准备: 构建多线程 web server
  构建计划:
  1. 学习一些 TCP 与 HTTP 知识
  2. 在嵌套字 (socket) 上监听 TCP 请求
  3. 解析少量的 HTTP 请求
  4. 创建一个合适的 HTTP 相应
  5. 通过线程池改善 server 的吞吐量

* 构建单线程 web server
  web server 中涉及到的两个主要协议是 *超文本传输协议* 和 *传输控制协议*. 这两者
  都是 *请求-相应* 协议, 也就是说, 有 *客户端(clien)* 来初始化请求, 并有 *服务
  端* 监听请求并向客户端提供相应. 请求与相应的内容本身定义.

  TCP 是一个底层协议, 它描述了信息如果从一个 server 到另一个 server 的细节, 不过
  其并不指定信息是什么. HTTP 构建于 TCP 之上, 它定义了请求和相应的内容. 为此, 技
  术上讲可将 HTTP 用于其他协议之上, 不过对于绝大部分情况, HTTP 通过 TCP 传输. 我
  们将要做的就是处理 TCP 和 HTTP 请求与相应的原始字节数据.

** 仔细观察 HTTP 请求
   HTTP 是一个基于文本的协议, 同时一个请求有如下格式
   #+begin_src text
     Method Request-URI HTTP-Version CRLF
     headers CRLF
     message-body
   #+end_src

   第一行叫做 *请求行(request line)*, 它存放了客户端请求了什么的信息. 请求行的第
   一部分是所使用的 method, 比如 ~GET~ 或 ~POST~, 这描述了客户端如何进行请求. 这
   里客户端使用了 ~GET~ 请求.

   请求行接下来的部分是 /, 它代表客户端请求的 *统一资源标识符*: 大体上类似, 但是
   也不完全类似于 URL(统一资源定位符). URI 和 URL 之间的区别对于本章的目的来说并
   不重要, 不过 HTTP 规范使用属于 URI, 这里可以简单地将 URL 理解为 URI.

   最后一部分是客户端使用的 HTTP 版本, 然后请求行以 *CRLF序列* (代表回车和换行
   carriage return line feed, 这是打字机时代的术语)结束. CRLF 序列也可以写成
   ~\r\n~. CRLF 序列将请求行与其余请求数据分开. 打印 CRLF 时, 我们会看到一个新行,
   而不是 ~\r\n~.

   目前运行程序中, ~GET~ 是 method, / 是请求 URI, 而 ~HTTP/1.1~ 是版本.

   从 ~Host:~ 开始的其余的行是 headers; ~GET~ 请求没有 body.

** 编写响应
   我们将实现在客户端请求的相应中发送数据的功能. 相应有如下格式:
   #+begin_src text
     HTTP-VERSION Status-Code Reason-Phrase CRLF
     headers CRLF
     message-body
   #+end_src

   第一行叫做 *状态行(status line)*, 它包含相应的 HTTP 版本, 一个数字状态码用以
   总结请求的结果和一个描述之前状态码的文本原因短语. CRLF 序列之后是任意 header,
   另一个 CRLF序列, 和响应的 body.

   一个使用 HTTP1.1 版本的响应例子, 状态码为 200, 原因短语为 OK, 没有 header, 也
   没有 body:
   #+begin_src text
     HTTP/1.1 200 OK\r\n\r\n
   #+end_src

   状态码 200 是一个标准的成功响应. 这些文本是一个微型的成功 HTTP 响应.

* 将单线程 server 变为多线程 server
  目前 server 会依次处理每一个请求, 意味着它在完成第一个连接的处理之前不会处理第
  二个连接. 如果 server 正接受越来越多的请求, 这类串行操作会使性能越来越差. 如果
  一个请求花费很长的时间来处理, 随后而来的请求则不得不等待这个长请求结束, 即便这
  些新请求可以很快就处理完. 我们需要修复这种情况

** 使用线程池改善吞吐量
   *线程池(thread pool)* 是一组预先分配的等待或准备处理任务的线程. 当程序收到一
   个新任务, 线程池中的一个线程会被分配任务, 这个线程会离开并处理任务. 其余的线
   程则可用于处理在第一个线程处理任务的同时处理其他接收到的任务. 当第一个线程处
   理完任务时, 它会返回空闲线程池中等待处理新任务. 线程池允许我们并发处理连接,
   增加 server 的吞吐量.

   我们会将池中线程限制为较少的数量, 以防拒绝服务(Denial of Service, DoS) 攻击;
   如果程序为每一个接受的请求都新建一个线程, 某人向 server 发起千万级的请求时会
   耗尽服务器的资源并导致所有请求的处理都被终止.

   不同于分配无限的线程, 线程池中将有固定数量的等待线程. 当新请求时, 将请求发送
   到线程池中做处理. 线程池会维护一个接收请求的队列. 每一个线程会从队列中取出一
   个请求, 处理请求, 接着向对队列索取另一个请求. 通过这种设计, 则可以并发处理
   ~N~ 个请求, 其中 ~N~ 为线程数. 如果每一个线程都在相应慢请求, 之后的请求仍然会
   阻塞队列, 不过相比之前增加了能处理的满请求的数量.

   这个设计仅仅是多种改善 web server 吞吐量的方法之一. 其他可供探索的方法有
   fork/join 模型和单线程异步 I/O 模型.

   当设计代码时, 首先编写客户端接口缺失有助于指导代码设计. 以期望的调用方式来构
   建 API 代码的结构, 接着在这个结构之内实现功能, 而不是先实现功能再设计公有
   API.

   类似于 TDD, 这里将要使用编译器驱动开发(compiler-driven development). 我们将编
   写调用所期望的函数的代码, 接着观察编译器错误告诉我们接下来需要修改什么使得代
   码可以工作.

** 采用编译器驱动构建 ThreadPool 结构体
   我们会在 ~ThreadPool~ 上定义 ~execute~ 函数来获取一个闭包函数. 闭包作为参数时
   可以使用三个不同的 trait: ~Fn~, ~FnMut~ 和 ~FnOnce~. 我们需要决定这里应该使用
   哪种闭包. 最终需要实现的类似于标准库的 ~thread::spawn~, 所以我们可以观察
   ~thread::spawn~ 的签名在其参数中使用了何种 bound. 阅读文档:
   #+begin_src rust
     pub fn spawn<F, T>(f: F) -> JoinHandle<T>
     where
         F: FnOnce() -> T + Send + 'static,
         T: Send + 'static
   #+end_src

   ~F~ 是这里我们关心的参数; ~T~ 与返回值有关所以我们并不关心. 考虑到 ~spawn~ 使
   用 ~FnOnce~ 作为 ~F~ 的 trait bound, 这可能也是我们需要的, 因为最终会传递给
   ~execute~ 的参数传给 ~spawn~. 因为处理请求的线程只会执行闭包一次, 这也进一步
   确认了 ~FnOnce~ 是我们需要的 trait, 这里符合 ~FnOnce~ 中 ~Once~ 的意思.

   ~F~ 还有 trait bound ~Send~ 和生命周期绑定 ~'static~, 这对我们的情况也是有意
   义的: 需要 ~Send~ 来将闭包从一个线程转移到另一个线程, 而 ~'static~ 是因为并不
   知道线程会执行多久. 

** 分配空间以存储线程
   现在有了一个有效的线程池线程数, 就可以实际创建这些线程并在返回之前将他们储存
   在 ~ThreadPool~ 结构体中.
   再次查看 ~thread::spawn~ 的签名:
   #+begin_src rust
     pub fn spawn<F, T>(f: F) -> JoinHandle<T>
     where
         F: FnOnce() -> T + Send + 'static,
         T: Send + 'static
   #+end_src

   ~spawn~ 返回 ~JoinHandle<T>~, 其中 ~T~ 是闭包返回的类型. 在我们的情况中, 传递
   给线程 池的闭包会处理连接并不返回任何值, 所以 ~T~ 将会是单元类型 ~()~. 

** Worker 结构体负责从 ThreadPool 中将代码传递给线程
   我们希望开始线程并等待稍后传递的代码, ~thread::spawn~ 是立刻执行的代码. 标准
   库中并没有包含这么做的方法.

   我们将要实现的行为是创建线程并稍后发送代码, 这会在 ~ThreadPool~ 和线程间引用
   一个新数据类型来管理这种新行为. 这个数据结构成为 ~Worker~: 这是一个池实现中的
   场景概念. 想象一下在餐馆厨房工作的员工: 员工等待来自客户的订单, 他们负责接受
   这些订单并完成它们.

   不同于在线程池中储存一个 ~JoinHandle<()>~ 实例的 vector, 我们会储存 ~Worker~
   结构体的实例. 每一个 ~Worker~ 会储存一个单独的 ~JoinHandle<()>~ 实例. 接着会
   在 ~Worker~ 上实现一个方法, 它会获取需要允许代码的闭包并将其发送给已经运行的
   线程执行. 我们还会赋予每一个 worker ~id~, 这样就可以在日志和调试中区别线程池
   中不的不同 worker.

   首先做出如此创建 ~ThreadPool~ 时所需的修改. 通过如下方式设置完 ~Worker~ 之后,
   实现向线程发送闭包的代码:
   1. 定义 ~Worker~ 结构体存放 ~id~ 和 ~JoinHandle<()>~
   2. 修改 ~ThreadPool~ 存放一个 ~Worker~ 实例的 vector
   3. 定义 ~Worker::new~ 函数, 它获取一个 ~id~ 数字并返回一个带有 ~id~ 和利用空
      闭包分配的线程的 ~Worker~ 实例.
   4. 在 ~ThreadPool::new~ 中, 使用 ~for~ 循环计数生成 ~id~, 使用这个 ~id~ 新建
      ~Worker~, 并储存进 vector 中.
   
** 使用通道向线程发送请求
   目前传递给 ~thread::spawn~ 的闭包完全没有做任何工作. 目前, 我们在 ~execute~
   方法中获得希望执行的闭包, 不过在创建 ~ThreadPool~ 的过程中创建每一个 ~Worker~
   时需要向 ~thread::spawn~ 传递一个闭包.

   我们希望刚创建的 ~Worker~ 结构体能够从 ~ThreadPool~ 的队列中获取需要执行的代
   码, 并发送到线程中执行他们.

   第 16 章我们学习了 *通道* -- 一个沟通两个线程的简单首端 -- 对于这个例子来说是
   绝佳的. 这里通道将充当任务队列的作用, ~execute~ 将通过 ~ThreadPool~ 向其中线
   程正在寻找工作的 ~Worker~ 实例发送任务. 如下计划:

   1. ~ThreadPool~ 会创建一个通道并充当发送端
   2. 每个 ~Worker~ 将会充当通道的接收端
   3. 新建一个 ~Job~ 结构体存放用于向通道中发送的闭包
   4. ~execute~ 方法会载通道发送端发出期望执行的任务
   5. 在线程中, ~Worker~ 会遍历通道的接收端并执行任何接收到的任务.

      
* 优雅停机与清理
  代码如期通过使用线程池异步的响应请求. 有些警告说 ~workers~, ~id~ 和 ~thread~
  字段没有直接被使用, 这提醒了我们并没有清理所有的你日日. 当使用 ctrl-c 终止主线
  程时, 所有其他线程也会立刻停止, 即使他们处理请求的过程中.

  现在我们要为 ~ThreadPool~ 实现 ~Drop~ trait 对线程池中的每一个线程调用 ~join~,
  这样这些线程将会执行完他们的请求. 接着会为 ~ThreadPool~ 实现一个告诉线程他们应
  该停止接收新请求并结束的方式. 为了实践这些代码, 修改 server 在优雅停机
  (graceful shutdown) 之前只接受 2 个请求

** 为 ThreadPool 实现 Drop Trait
   当线程池被丢弃时, 应该 join 所有线程以确保他们完成其操作.

** 向线程发送信号使其停止接收任务
   这些代码还不能以我们期望的方式允许. 问题的关键在于 ~Worker~ 中分配的线程所运
   行的闭包中的逻辑: 调用 ~join~ 并不会关闭线程, 因为 ~loop~ 会一直寻找任务. 如
   果采用这个实现来尝试丢弃 ~ThreadPool~, 则主线程会永远阻塞在等待第一个线程结束
   上.

   为了修复这个问题, 修改线程既监听是否有 ~Job~ 运行也要监听一个应该停止监听并退
   出无限循环的信号. 所以通道应该发送枚举而不是 ~Job~ 实例

